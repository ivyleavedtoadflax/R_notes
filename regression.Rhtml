<html>

<head>
<title>Getting Started with R - Linear regression</title>
<link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>

<table align="center" width="80%">
<tr>
<td class="next"><a href="t-test.html">Previous</a></td>
<td class="next"><a href="index.html">Course Overview</a></td>
<td class="next"><a href="ANOVA.html">Next</a></td>
</tr>
</table>

<br><hr class="ex1"><br>

<h1>Linear regression</h1>

<p>Linear regression can be completed in a similarly uncomplicated way in <tt>R</tt>. In this example, we will revisit the <tt>trees</tt> dataset we used earlier</p>

<!--begin.rcode,tidy=FALSE
trees
end.rcode-->

<p>Now let us assume that there is likely to be a correlation between <tt>Girth</tt> and <tt>Volume</tt>, and we want to examine this with a linear model.</p>

<p>We start by plotting the data</p>

<!--begin.rcode,"regression1",tidy=FALSE

with(
     trees,
     plot(
          x = Girth,
          y = Volume
          )
     )
end.rcode-->

<p>So it looks like there is a positive relationship...let's explore this with linear regression. We specify a model formula of <tt>Volume ~ Girth</tt>, which means <tt>Volume</tt> is dependent on <tt>Girth</tt>.</p>

<!--begin.rcode,tidy=FALSE
model <- lm(
     formula = Volume ~ Girth,
     data = trees
     )
end.rcode-->

<p>We must call the results of the test with <tt>summary</tt>.</p>

<!--begin.rcode,tidy=FALSE
summary(model)
end.rcode-->

<p>So we get quite a lot of output...</p>

<p>First we are reminded of the model we called:</p>

<!--begin.rcode,tidy=FALSE,echo=FALSE
model$call
end.rcode-->

<p>Then we get some summary information from the residuals - the minimum, maximum, median, and the 1st and 3rd quartiles. Remember that our residuals should be normally distributed in a regression model, so we can get an initial idea of whether this is so from this summary:</p>

<!--begin.rcode,tidy=FALSE,echo=FALSE
summary(model$residuals)
end.rcode-->

<p>Then we get the juicy stuff...</p>

<!--begin.rcode,tidy=FALSE,echo=FALSE
(summary(model))$coefficients
end.rcode-->

<p>First we get the model coefficients. Note that the name of the response variable (Volume) has been replaced with <tt>(Intercept)</tt>, and the first value immediately to the right of this is the intercept of our regression line. The number beneath this is the slope of our regression line - hence these two can be considered as &alpha; and &beta; in the equation <tt>y = &alpha; + &beta;x</tt></p>

<p>Hence we can use them to plot the regression line represented by the model with:</p>

<!--begin.rcode,"regression2",tidy=FALSE
     
plot(
     x = trees$Girth,
     y = trees$Volume
     )

abline(
     a = coef(model[1]),
     b = coef(model[2]) 
     )

# Or more simply:

abline(model)
end.rcode-->

<p>We also get the results from t-tests on the two variables:</p>

<!--begin.rcode,tidy=FALSE,echo=FALSE
(summary(model))$coefficients
end.rcode-->

<p>The number of interest to us is <tt><0.00276**</tt>, which tells us that there is a significant correlation (which is positive because the t value <tt>3.272</tt> is also positive) between <tt>Volume</tt> and <tt>Girth</tt></p>

<p>Other pertinent information is the r-square (R<sup>2</sup>) and adjusted-r-squared values (<span style="text-decoration: overline">R</span><sup>2</sup>). If you don't know what these are you should look them up: <a href="http://en.wikipedia.org/wiki/R-squared">http://en.wikipedia.org/wiki/R-squared</a>.</p>

<p>If we want to include this information on the graph, we can:</p>

<!--begin.rcode,"regression3",tidy=FALSE
     
plot(
     x = trees$Girth,
     y = trees$Volume,
     pch = 16,
     col = "hotpink",
     cex = 1.4
     )

abline(model)

formula_text <- paste(
     "y=",
     round(coef(model)[1],2),
     "+",
     round(coef(model)[2],2),
     "x, ",
     sep=""
     )

rsquared_text = paste(
     "=",
     round(
     (summary(model))$r.squared
     ,2
     )
     )



text(
     substitute(
          paste(ft, R^2, rt), 
          list(ft=formula_text,rt = rsquared_text)
          ),
     x = 12,
     y = 75
     )
end.rcode-->

<p>All good - but we do need to check the model diagnostic plots to ensure that we have met the assumptions of a linear model.</p>

<!--begin.rcode,"regression4",tidy=FALSE,fig.height=25
par(mfrow=c(4,1))

plot(model)

par(mfrow=c(1,1))
end.rcode-->

<p>As I keep saying, this is not a statistics course. If you don't know what you are looking at here, You should find.</p>

<p>These plots are discussed in the R book on p.357, but in general terms the first and third plot should should look like a sky at night, without any particular patternation - and in particular the data should not be clustered in a wedge shape. The second plot should generally follow the straight line indicated - this is the same as the <tt>qqnorm</tt> plot discussed elsewhere in the course.</p>

<h2>Transformation</h2>

<p>The astute amongst you may have noticed that we could improve the fit of the model by transforming the data - probably with a log transformation.</p>

<p>Let's try this now:</p>

<!--begin.rcode,tidy=FALSE
model1 <- lm(
     formula = log10(Volume) ~ log10(Girth),
     data = trees
     )
summary(model1)
end.rcode-->

<p>Yes, the R-squared is slightly better than with the transformed model. Now let's reproduce the plot, this time with log10 transformed axes:</p>


<!--begin.rcode,"regression5",tidy=FALSE,fig.height=12

par(mfrow=c(2,1))

plot(
     x = trees$Girth,
     y = trees$Volume,
     pch = 16,
     col = "hotpink",
     cex = 1.4,
     main = "Untransformed"
     )

abline(model)

plot(
     x = trees$Girth,
     y = trees$Volume,
     pch = 16,
     col = "hotpink",
     cex = 1.4,
     log = "xy",
     main = "Transformed"
     )

abline(model1)

par(mfrow=c(1,1))

end.rcode-->

<p>A nice touch when plotting data on transformed axes, is to produce a plot of the original data within the first plot with the model line plotted untransformed.</p>

<!--begin.rcode,"regression6",tidy=FALSE

# Create intial plot

plot(
     x = trees$Girth,
     y = trees$Volume,
     pch = 16,
     col = "hotpink",
     cex = 1.4,
     log = "xy",
     main = "Volume ~ Girth ",
     bty = "l",
     xlab = "Girth (in)",
     ylab = bquote(Volume~(ft^3)),
     yaxt = "n"
     )

axis(
     side = 2,
     las = 2
     )

# Pot regression line

abline(
     model1,
     lty = 2,
     lwd = 2,
     col = rgb(0,0,1,0.5)
     )


# Set up graphical parameters for sub plot see ?par

par(
     fig = c(0.6,1,0.075,0.6),  
     new = T,
     bty = "o",
     cex.axis = 0.8,
     cex.lab = 0.8,
     mgp = c( 1.95, 0.3, 0),
     tck = -0.02
)

# Plot sub plot
# Note that x and y axes have been suppressed, as have annotations

plot(
     x = trees$Girth,
     y = trees$Volume,
     pch = 16,
     col = "hotpink",
     ann = FALSE,
     xlim = c(5,20),
     ylim = c(5,70),
     xaxt = "n",
     yaxt = "n"
     )

# Use predict to calculate the untransformed model. Note the untf=T

lines(
     10 ^ predict(
          model1,
          list(Girth = 1:50),
          untf = T
          ),
     lty = 1,
     lwd = 2,
     col = rgb(0,0,1,0.5)
)

# Add x-axis

axis(
     side=1, 
     at = seq(0,20,5), 
     lwd = 0.5
)

# Add y-axis

axis(
     side = 2,
     at = seq(0,100,20), 
     las = 2, 
     lwd = 0.5
)

# Reset the plotting parameters

par(
     fig=c(0,1,0,1),  
     new = F
)
end.rcode-->

<p>Finally, we should check the model assumptions again...</p>

<!--begin.rcode,"regression7",tidy=FALSE,fig.height=25

par(mfrow=c(4,1))
plot(model1)
par(mfrow=c(1,1))

end.rcode-->

<p>The diagnostic plots seem to be a little better for the transformed data. Hence it seems like a justified choice to transform the data.</p>

<br><hr class="ex1"><br>

<table align="center" width="80%">
<tr>
<td class="next"><a href="t-test.html">Previous</a></td>
<td class="next"><a href="index.html">Course Overview</a></td>
<td class="next"><a href="ANOVA.html">Next</a></td>
</tr>
</table>

</body>

</html>
